import streamlit as st
import ollama
import pdfplumber
import json
import os
import re
import time
import io
import pandas as pd
from datetime import datetime

# --- è¨­å®šèˆ‡åˆå§‹åŒ– ---
SAVE_DIR = "projects"
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

st.set_page_config(page_title="AI æ–‡ç»åˆ†ç´šå·¥ä½œç«™ Pro v3.9.7", page_icon="ğŸ“", layout="wide")

# CSS æ¨£å¼å„ªåŒ–
st.markdown("""
    <style>
    /* å³ä¸Šè§’ç³»çµ±æ™‚é–“æ¨£å¼ */
    .system-time-container {
        position: fixed;
        top: 3.5rem;
        right: 1.5rem;
        background-color: rgba(255, 255, 255, 0.9);
        padding: 6px 16px;
        border-radius: 20px;
        border: 1px solid #d1d5db;
        z-index: 999999;
        font-family: 'Courier New', monospace;
        font-size: 0.85rem;
        color: #1f2937;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        font-weight: bold;
    }
    
    [data-testid="stMetricValue"] { font-size: 1.2rem !important; }
    
    /* å¼·åˆ¶æŒ‰éˆ•æ–‡å­—ä¸æ›è¡Œ */
    .stButton > button { 
        padding: 2px 10px; 
        font-size: 0.85rem; 
        white-space: nowrap; /* ç¢ºä¿æ–‡å­—åœ¨åŒä¸€è¡Œ */
    }
    
    /* ä¿®æ­£ Toggle æ¨™ç±¤åŒä¸€è¡Œ */
    .stWidget label {
        white-space: nowrap !important;
    }

    .doc-meta { 
        font-size: 1.05rem !important; 
        font-weight: 500;
        color: #1E1E1E; 
        background-color: #f0f2f6;
        padding: 10px 15px;
        border-radius: 8px;
        margin-bottom: 10px;
        border-left: 5px solid #007bff;
    }
    .stTabs [data-baseweb="tab-list"] { gap: 24px; }
    .stTabs [data-baseweb="tab"] { height: 50px; white-space: pre-wrap; }
    .stProgress > div > div > div > div { background-color: #007bff; }
    .instant-report {
        padding: 15px;
        border: 1px solid #e6e9ef;
        border-radius: 10px;
        background-color: #ffffff;
        margin-bottom: 20px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .time-tag {
        font-size: 0.8rem;
        color: #6c757d;
        font-family: monospace;
    }
    </style>
    """, unsafe_allow_html=True)

# --- é¡¯ç¤ºå‹•æ…‹æ™‚é–“ ---
time_placeholder = st.empty()
current_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
time_placeholder.markdown(f'<div class="system-time-container">â³ ç³»çµ±æ™‚é–“ï¼š{current_time_str}</div>', unsafe_allow_html=True)

# --- è¼”åŠ©å‡½å¼åº« ---
def clean_author_info(author_data):
    if not author_data: return "æœªçŸ¥"
    if isinstance(author_data, list):
        items = [clean_author_info(i) for i in author_data]
        return ", ".join(items)
    if isinstance(author_data, dict):
        return author_data.get('name', str(author_data))
    return str(author_data)

def ensure_str(val):
    if val is None: return "ç„¡è³‡æ–™"
    if isinstance(val, list):
        cleaned_list = [str(i).strip().strip("'").strip('"') for i in val if i]
        return "\n".join([f"â€¢ {item}" for item in cleaned_list]) if cleaned_list else "ç„¡è³‡æ–™"
    if isinstance(val, dict):
        cleaned_vals = [ensure_str(v) for v in val.values()]
        return "\n".join(cleaned_vals)
    s = str(val).strip()
    if (s.startswith("'") and s.endswith("'")) or (s.startswith('"') and s.endswith('"')):
        s = s[1:-1].strip()
    if (s.startswith("{") and s.endswith("}")) or (s.startswith("[") and s.endswith("]")):
        try:
            import ast
            parsed = ast.literal_eval(s)
            if isinstance(parsed, dict):
                return "\n".join([f"â€¢ {v}" if isinstance(v, str) else ensure_str(v) for v in parsed.values()])
            if isinstance(parsed, list):
                return ensure_str(parsed)
        except:
            s = re.sub(r"['\"]?\w+['\"]?\s*:\s*", "", s) 
            s = s.strip("{}[]").replace("'", "").replace('"', "").strip()
    return s

def save_project_data(name, data):
    data["last_accessed"] = time.time()
    with open(os.path.join(SAVE_DIR, f"{name}.json"), "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def load_project_data(name):
    path = os.path.join(SAVE_DIR, f"{name}.json")
    default_data = {"messages": [], "documents": {}, "last_accessed": time.time()}
    if not os.path.exists(path): return default_data
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if "documents" not in data: data["documents"] = {}
            if "messages" not in data: data["messages"] = []
            return data
    except: return default_data

def ask_ai_json(content, model):
    system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç ”ç©¶åŠ©ç†ã€‚è«‹åˆ†ææ–‡ç»å…§å®¹ä¸¦åš´æ ¼æŒ‰ç…§ JSON æ ¼å¼å›ç­”ã€‚
    ä½ å¿…é ˆæå–ä¸¦ç¸½çµå‡ºä»¥ä¸‹ã€äº”å€‹ä¸»é¡Œã€ï¼Œæ¯å€‹æ¬„ä½å¿…é ˆæ˜¯ã€å–®ä¸€ç´”æ–‡å­—å­—ä¸²ã€ï¼š
    1. topic: ç ”ç©¶ä¸»é¡Œ
    2. goals: ç ”ç©¶ç›®æ¨™
    3. method: ç ”ç©¶æ–¹æ³•
    4. findings: æ‘˜è¦èˆ‡ç™¼ç¾
    5. limitations: ä¾·é™æ€§èˆ‡å»ºè­°
    - author: ä½œè€…å§“å
    - year: å‡ºç‰ˆå¹´ä»½
    èªç³»ï¼šç¹é«”ä¸­æ–‡ã€‚"""
    user_prompt = f"åˆ†æä»¥ä¸‹æ–‡ç»å…§å®¹ï¼Œç›´æ¥è¼¸å‡º JSON ç‰©ä»¶ï¼š\n\n{content[:10000]}"
    try:
        response = ollama.chat(model=model, messages=[
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': user_prompt}
        ])
        raw_content = response['message']['content']
        clean_json = re.sub(r'```json|```', '', raw_content).strip()
        json_match = re.search(r'\{.*\}', clean_json, re.DOTALL)
        if json_match:
            res = json.loads(json_match.group())
            return {k: ensure_str(v) for k, v in res.items()}
        return None
    except: return None

# --- åˆå§‹åŒ– Session State ---
if 'selected_project' not in st.session_state:
    st.session_state.selected_project = "è«‹é¸æ“‡"

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸš€ ç³»çµ±æ§åˆ¶å°")
    selected_model = st.selectbox("æ ¸å¿ƒæ¨¡å‹", ["llama3:8b-instruct-q4_0", "llava", "phi3"], index=0)
    st.divider()
    
    project_files = []
    for f in os.listdir(SAVE_DIR):
        if f.endswith(".json"):
            name = f.replace(".json", "")
            data = load_project_data(name)
            project_files.append({"name": name, "last_accessed": data.get("last_accessed", 0)})
    
    project_files.sort(key=lambda x: x['last_accessed'], reverse=True)
    recent_names = [p['name'] for p in project_files]

    if recent_names:
        st.subheader("ğŸ•’ æœ€è¿‘ä½¿ç”¨çš„å°ˆæ¡ˆ")
        for i, proj_name in enumerate(recent_names[:3]):
            if st.button(f"ğŸ“ {proj_name}", key=f"recent_{i}", use_container_width=True):
                st.session_state.selected_project = proj_name
                st.rerun()
    st.divider()

    selected = st.selectbox("é¸æ“‡å°ˆæ¡ˆ", ["è«‹é¸æ“‡"] + recent_names, index=0 if st.session_state.selected_project == "è«‹é¸æ“‡" else recent_names.index(st.session_state.selected_project)+1 if st.session_state.selected_project in recent_names else 0)
    if selected != st.session_state.selected_project:
        st.session_state.selected_project = selected
        st.rerun()

    # --- åˆªé™¤å°ˆæ¡ˆåŠŸèƒ½ (é›™é‡ç¢ºèª) ---
    if st.session_state.selected_project != "è«‹é¸æ“‡":
        with st.popover("ğŸ—‘ï¸ åˆªé™¤ç›®å‰å°ˆæ¡ˆ", use_container_width=True):
            st.warning(f"ç¢ºå®šè¦æ°¸ä¹…åˆªé™¤å°ˆæ¡ˆã€Œ{st.session_state.selected_project}ã€å—ï¼Ÿé€™å°‡ç„¡æ³•å¾©åŸã€‚")
            if st.button("ğŸ”¥ ç¢ºå®šåˆªé™¤", use_container_width=True, type="primary"):
                file_path = os.path.join(SAVE_DIR, f"{st.session_state.selected_project}.json")
                if os.path.exists(file_path):
                    os.remove(file_path)
                    st.session_state.selected_project = "è«‹é¸æ“‡"
                    st.success("å°ˆæ¡ˆå·²åˆªé™¤")
                    time.sleep(1)
                    st.rerun()

    st.divider()
    new_p_name = st.text_input("âœ¨ å»ºç«‹æ–°å°ˆæ¡ˆ")
    if st.button("ç¢ºèªæ–°å¢", use_container_width=True) and new_p_name:
        save_project_data(new_p_name, {"messages": [], "documents": {}, "last_accessed": time.time()})
        st.session_state.selected_project = new_p_name
        st.rerun()

# --- ä¸»ç•«é¢ ---
current_p = st.session_state.selected_project
if current_p != "è«‹é¸æ“‡":
    project_data = load_project_data(current_p)
    st.header(f"ğŸ—ƒï¸ å°ˆæ¡ˆï¼š{current_p}")
    docs = project_data.get("documents", {})

    tab_manage, tab_matrix, tab_chat = st.tabs(["ğŸ“‚ è‡ªå‹•æ•´ç†æ–‡ç»", "ğŸ“Š æ¯”è¼ƒçŸ©é™£", "ğŸ’¬ æ·±åº¦å°è©±"])

    with tab_manage:
        uploaded_files = st.file_uploader("ğŸ“¥ æ‰¹æ¬¡ä¸Šå‚³æ–‡ç»", type=['pdf', 'txt'], accept_multiple_files=True)
        
        if uploaded_files:
            files_to_process = [f for f in uploaded_files if f.name not in docs]
            if files_to_process:
                st.markdown("### âš¡ AI å³æ™‚åˆ†æé€²åº¦")
                pb = st.progress(0)
                status_text = st.empty()
                live_output = st.container() 
                for idx, f in enumerate(files_to_process):
                    start_time = time.time()
                    status_text.text(f"æ­£åœ¨è™•ç†: {f.name}...")
                    content = ""
                    if f.name.endswith(".pdf"):
                        try:
                            with pdfplumber.open(io.BytesIO(f.read())) as pdf:
                                content = "\n".join([p.extract_text() for p in pdf.pages[:10] if p.extract_text()])
                        except: st.error(f"è®€å–å¤±æ•—: {f.name}")
                    else:
                        content = f.read().decode("utf-8")
                    if content:
                        meta = ask_ai_json(content, selected_model)
                        process_duration = round(time.time() - start_time, 2)
                        doc_entry = {
                            "content": content,
                            "metadata": {
                                "title": f.name,
                                "author": meta.get('author', 'æœªçŸ¥') if meta else 'æœªçŸ¥',
                                "year": meta.get('year', 'æœªçŸ¥') if meta else 'æœªçŸ¥',
                                "timestamp": time.time(),
                                "duration": process_duration
                            },
                            "full_report": meta if meta else {}
                        }
                        project_data["documents"][f.name] = doc_entry
                        save_project_data(current_p, project_data)
                        with live_output:
                            st.markdown(f"""
                            <div class="instant-report">
                                <div style="display: flex; justify-content: space-between;">
                                    <h4 style="color:#007bff; margin:0;">âœ… å·²å®Œæˆï¼š{f.name}</h4>
                                    <span class="time-tag">â±ï¸ è€—æ™‚: {process_duration}s</span>
                                </div>
                                <hr style="margin:10px 0;">
                                <b>ğŸ“Œ ç ”ç©¶ç™¼ç¾æ‘˜è¦ï¼š</b><br>{ensure_str(meta.get('findings'))[:300]}...
                            </div>
                            """, unsafe_allow_html=True)
                    pb.progress((idx + 1) / len(files_to_process))
                st.success("ğŸ‰ æ‰€æœ‰æª”æ¡ˆè™•ç†å®Œç•¢ï¼")
                time.sleep(1)
                st.rerun()

        st.divider()
        
        sorted_docs = sorted(docs.items(), key=lambda x: x[1].get("metadata", {}).get("timestamp", 0), reverse=True)
        
        if not sorted_docs:
            st.warning("ç›®å‰æš«ç„¡æ–‡ç»ï¼Œè«‹å¾ä¸Šæ–¹ä¸Šå‚³æª”æ¡ˆä»¥å•Ÿå‹• AI è‡ªå‹•æ•´ç†ã€‚")
        else:
            search_query = st.text_input("ğŸ” é—œéµå­—æœå°‹...", key="search_bar").lower()
            for doc_id, info in sorted_docs:
                m = info.get("metadata", {})
                r = info.get("full_report") or {}
                if search_query and search_query not in doc_id.lower() and search_query not in str(r).lower():
                    continue

                doc_date = datetime.fromtimestamp(m.get('timestamp', 0)).strftime('%Y-%m-%d %H:%M')
                
                with st.expander(f"ğŸ“„ {m.get('title', doc_id)} - {doc_date} (â±ï¸{m.get('duration', '?')}s)"):
                    c_edit, c_del, c_space = st.columns([1.5, 1.5, 7])
                    with c_edit:
                        is_editing = st.toggle("ğŸ“ ç·¨è¼¯", key=f"edit_toggle_{doc_id}")
                    with c_del:
                        if st.button("ğŸ—‘ï¸ åˆªé™¤", key=f"del_{doc_id}", use_container_width=True):
                            del project_data["documents"][doc_id]
                            save_project_data(current_p, project_data)
                            st.rerun()

                    if is_editing:
                        new_author = st.text_input("ğŸ‘¤ ä½œè€…", value=m.get('author', 'æœªçŸ¥'), key=f"in_auth_{doc_id}")
                        new_year = st.text_input("ğŸ“… å¹´ä»½", value=m.get('year', 'æœªçŸ¥'), key=f"in_year_{doc_id}")
                        col1, col2 = st.columns(2)
                        with col1:
                            new_topic = st.text_area("ğŸ“š ç ”ç©¶ä¸»é¡Œ", value=r.get('topic', ''), key=f"in_topic_{doc_id}")
                            new_goals = st.text_area("ğŸ¯ ç ”ç©¶ç›®æ¨™", value=r.get('goals', ''), key=f"in_goals_{doc_id}")
                        with col2:
                            new_method = st.text_area("ğŸ§ª ç ”ç©¶æ–¹æ³•", value=r.get('method', ''), key=f"in_method_{doc_id}")
                            new_limit = st.text_area("âš ï¸ ä¾·é™æ€§èˆ‡å»ºè­°", value=r.get('limitations', ''), key=f"in_limit_{doc_id}")
                        new_findings = st.text_area("ğŸ’¡ æ‘˜è¦èˆ‡ç™¼ç¾", value=r.get('findings', ''), key=f"in_find_{doc_id}")
                        
                        if st.button("ğŸ’¾ å„²å­˜ä¿®æ”¹", key=f"save_edit_{doc_id}", type="primary"):
                            project_data["documents"][doc_id]["metadata"]["author"] = new_author
                            project_data["documents"][doc_id]["metadata"]["year"] = new_year
                            project_data["documents"][doc_id]["full_report"] = {
                                "topic": new_topic, "goals": new_goals, "method": new_method,
                                "findings": new_findings, "limitations": new_limit,
                                "author": new_author, "year": new_year
                            }
                            save_project_data(current_p, project_data)
                            st.success("æ›´æ–°æˆåŠŸï¼")
                            time.sleep(0.5)
                            st.rerun()
                    else:
                        st.markdown(f"<div class='doc-meta'>ğŸ‘¤ ä½œè€…ï¼š{clean_author_info(m.get('author'))} | å¹´ä»½ï¼š{m.get('year','æœªçŸ¥')}</div>", unsafe_allow_html=True)
                        col1, col2 = st.columns(2)
                        with col1:
                            st.info(f"**ğŸ“š ç ”ç©¶ä¸»é¡Œ**\n\n{ensure_str(r.get('topic'))}")
                            st.info(f"**ğŸ¯ ç ”ç©¶ç›®æ¨™**\n\n{ensure_str(r.get('goals'))}")
                        with col2:
                            st.warning(f"**ğŸ§ª ç ”ç©¶æ–¹æ³•**\n\n{ensure_str(r.get('method'))}")
                            st.error(f"**âš ï¸ ä¾·é™æ€§èˆ‡å»ºè­°**\n\n{ensure_str(r.get('limitations'))}")
                        st.success(f"**ğŸ’¡ æ‘˜è¦èˆ‡ç™¼ç¾**\n\n{ensure_str(r.get('findings'))}")

    with tab_matrix:
        st.subheader("ğŸ“Š é—œéµæŒ‡æ¨™å°ç…§çŸ©é™£")
        if docs:
            matrix_list = []
            for d in docs.values():
                fr = d.get("full_report", {})
                matrix_list.append({
                    "æ–‡ç»æ¨™é¡Œ": d['metadata'].get("title"),
                    "ç ”ç©¶ä¸»é¡Œ": ensure_str(fr.get("topic")),
                    "ç ”ç©¶æ–¹æ³•": ensure_str(fr.get("method")),
                    "æ‘˜è¦ç™¼ç¾": ensure_str(fr.get("findings")),
                    "ä¾·é™å»ºè­°": ensure_str(fr.get("limitations")),
                    "ä½œè€…": clean_author_info(d['metadata'].get("author")),
                    "å¹´ä»½": d['metadata'].get("year")
                })
            df = pd.DataFrame(matrix_list)
            st.dataframe(df, use_container_width=True)
            st.download_button("ğŸ“¥ ä¸‹è¼‰çŸ©é™£ (CSV)", df.to_csv(index=False).encode('utf-8-sig'), f"{current_p}_matrix.csv", "text/csv")
        else: st.info("å°šç„¡æ•¸æ“šã€‚")

    with tab_chat:
        c1, c2 = st.columns([8, 2])
        with c1:
            st.subheader("ğŸ’¬ èˆ‡ AI æ·±åº¦å°è©±")
        with c2:
            if st.button("ğŸ§¹ æ¸…é™¤å°è©±æ­·å²", use_container_width=True):
                project_data["messages"] = []
                save_project_data(current_p, project_data)
                st.rerun()
        
        for msg in project_data.get("messages", []):
            with st.chat_message(msg["role"]): st.write(msg["content"])
            
        if prompt := st.chat_input("è©¢å•æœ‰é—œæœ¬å°ˆæ¡ˆæ–‡ç»çš„ç´°ç¯€..."):
            with st.chat_message("user"): st.write(prompt)
            knowledge = "\n".join([f"æª”æ¡ˆ:{k}\nå…§å®¹é‡é»:{str(v.get('full_report',''))}" for k, v in docs.items()])
            with st.chat_message("assistant"):
                res_box = st.empty(); full_res = ""
                for chunk in ollama.chat(model=selected_model, messages=[{'role': 'user', 'content': f"ä½ æ˜¯ä¸€å€‹ç ”ç©¶åŠ©ç†ï¼Œæ ¹æ“šæ–‡ç»å›ç­”ï¼š\n{knowledge}\nå•é¡Œï¼š{prompt}"}], stream=True):
                    full_res += chunk['message']['content']; res_box.markdown(full_res + "â–Œ")
                res_box.markdown(full_res)
            project_data["messages"].append({"role": "user", "content": prompt})
            project_data["messages"].append({"role": "assistant", "content": full_res})
            save_project_data(current_p, project_data)
else:
    st.info("ğŸ’¡ è«‹å¾å·¦å´å´é‚Šæ¬„é¸æ“‡å°ˆæ¡ˆæˆ–å»ºç«‹æ–°å°ˆæ¡ˆä»¥é–‹å§‹å·¥ä½œã€‚")